{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in country to country coverage intensity for all themes combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing libraries, functions and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# set relative path\n",
    "countries_capitals_path = '../../data/auxilary_data/countries_capitals.csv'\n",
    "data_folder_path = '../../data/GDELT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_capitals = pd.read_csv(countries_capitals_path)\n",
    "\n",
    "# make a countries dictionary with FIPS as key\n",
    "countries = countries_capitals.set_index('FIPS')['Country'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the functions from our scraping_gdelt notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def querybuilder(dict):\n",
    "    base_url = \"https://api.gdeltproject.org/api/v2/doc/doc?\"\n",
    "    url = base_url + \"&\".join([f\"{key}={value}\" for key, value in dict.items()])\n",
    "    url = urllib.parse.quote(url, safe='():/?&=').replace(\"&theme=\", \"%20theme:\")\n",
    "    return url\n",
    "\n",
    "def get_gdelt_data(theme, country, start_date, end_date, verbose=0):\n",
    "    \n",
    "    if theme == \"ALL\":\n",
    "        dict = {\n",
    "            \"query\": query_dict[country],\n",
    "            \"mode\": \"TimelineSourceCountry\",\n",
    "            \"startdatetime\": start_date,\n",
    "            \"enddatetime\": end_date,\n",
    "            \"format\": \"csv\",\n",
    "            \"timezoom\" : \"yes\",\n",
    "        }\n",
    "    else:\n",
    "        dict = {\n",
    "            \"query\": query_dict[country],\n",
    "            \"theme\": theme,\n",
    "            \"mode\": \"TimelineSourceCountry\",\n",
    "            \"startdatetime\": start_date,\n",
    "            \"enddatetime\": end_date,\n",
    "            \"format\": \"csv\",\n",
    "            \"timezoom\" : \"yes\",\n",
    "        }  \n",
    "        \n",
    "    url = querybuilder(dict)\n",
    "    \n",
    "    if verbose >= 2:\n",
    "        print(url.replace(\"csv\", \"html\"))\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError:\n",
    "        if verbose >= 2:\n",
    "            print(\"passed\")\n",
    "        pass\n",
    "\n",
    "def format_seconds(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = seconds % 60\n",
    "    if hours > 0:\n",
    "        return f\"{hours} hours, {minutes} minutes, {round(seconds)} seconds\"\n",
    "    elif minutes > 0:\n",
    "        return f\"{minutes} minutes, {round(seconds)} seconds\"\n",
    "    else:\n",
    "        return f\"{round(seconds, 2)} seconds\"\n",
    "\n",
    "def scrape_gdelt(themes, countries, start_date, end_date, save_int, all=False, verbose=0):\n",
    "    df_list = []\n",
    "    \n",
    "    if all:\n",
    "        themes.append(\"ALL\")\n",
    "\n",
    "    # track time left\n",
    "    total_items = len(themes) * len(countries)\n",
    "    count = 0\n",
    "    api_call_times = []\n",
    "    passed_total = 0\n",
    "    if verbose >= 1:\n",
    "        print(f\"Total queries: {total_items}\")\n",
    "    # set current time\n",
    "    start_time = time.time()\n",
    "                \n",
    "    saved = 0\n",
    "\n",
    "    for theme in themes:\n",
    "        for country in countries:\n",
    "            if verbose >= 2:\n",
    "                print(f\"Scraping {theme} in {country}\")\n",
    "            \n",
    "            # set time when api was called last\n",
    "            last_api_call_time = time.time()\n",
    "\n",
    "            df = get_gdelt_data(theme, country, start_date, end_date, verbose=verbose)\n",
    "            \n",
    "            api_call_times.append(time.time() - last_api_call_time)\n",
    "\n",
    "            if df is not None:\n",
    "                df['theme'] = theme\n",
    "                df['country'] = country\n",
    "                df_list.append(df)\n",
    "            else:\n",
    "                passed_total += 1\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if count % save_int == 0:\n",
    "                df = pd.concat(df_list)\n",
    "                df.to_csv(f'{data_folder_path}scraped_all/gdelt_data_{count-save_int}_to_{count}.csv')\n",
    "                df_list = []\n",
    "                saved += 1\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            items_per_second = count / elapsed_time\n",
    "            seconds_left = (total_items - count) / items_per_second\n",
    "            \n",
    "            progress_str = f\"Processed {count}/{total_items} queries. {round(items_per_second, 2)} Query/s. Average api time: {round(sum(api_call_times)/len(api_call_times),2)}s. On theme {theme} for {country}                           \\\n",
    "                            \\nElapsed time: {elapsed_time:.2f} seconds. Estimated time left: {format_seconds(seconds_left)}. Saved: {saved}\"\n",
    "            sys.stdout.write('\\x1b[A\\r' + progress_str)\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # avoid hitting API rate limit\n",
    "            if time.time() - last_api_call_time < 5:\n",
    "                time.sleep(5 - (time.time() - last_api_call_time))\n",
    "                \n",
    "    df = pd.concat(df_list)\n",
    "    df.to_csv(f'{data_folder_path}scraped_all/gdelt_data_{count-save_int}_to_{count}.csv')\n",
    "    df_list = []\n",
    "    saved += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scraping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up the parameters for our scraping operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_all = [str(item) for item in countries.keys()]\n",
    "themes_all = []\n",
    "\n",
    "start_date = \"20170101010000\"\n",
    "end_date = \"20240301010000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we call the scraping function, which saves csv's every 20 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_gdelt(themes_all, countries_all, start_date, end_date, save_int=20, all=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read the saves csv files back in\n",
    "\n",
    "Since the data is too large for pandas (and our kernel) to handle at once, we have to read in and save the csv in 2 batches. We first make a function to wrangle the data in the desired format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_batch(batch):\n",
    "    if \"Unnamed: 0\" in batch.columns:\n",
    "        batch.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    batch.columns = [\"Date\", \"Source country\", \"Intensity\", \"Theme\", \"Target country\"]\n",
    "    batch[\"Source country\"] = batch[\"Source country\"].str.replace(\" Volume Intensity\", \"\")\n",
    "    batch[\"Target country\"] = batch[\"Target country\"].map(countries)\n",
    "    batch_pivot = batch.pivot_table(index=[\"Date\", \"Target country\"], columns=[\"Source country\"], values=\"Intensity\").reset_index()\n",
    "    return batch_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then read in all the csv's in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening df 5 from scraped_all/gdelt_data_80_to_100.csv....\r"
     ]
    }
   ],
   "source": [
    "# for csv file in scraped_all folder\n",
    "csv_files = glob.glob(f'{data_folder_path}scraped_all/*.csv')\n",
    "\n",
    "# first batch\n",
    "dataframes = []\n",
    "for i, file in enumerate(csv_files[6:]):\n",
    "    print(f\"Opening df {i} from {file}...\", end=\"\\r\")\n",
    "    df = pd.read_csv(file)\n",
    "    batch = wrangle_batch(df)\n",
    "    dataframes.append(batch)\n",
    "\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "data.to_csv(f\"{data_folder_path}/scraped_all/combined_1.csv\", index=False)\n",
    "\n",
    "# second batch\n",
    "dataframes = []\n",
    "for i, file in enumerate(csv_files[6:]):\n",
    "    print(f\"Opening df {i} from {file}...\", end=\"\\r\")\n",
    "    df = pd.read_csv(file)\n",
    "    batch = wrangle_batch(df)\n",
    "    dataframes.append(batch)\n",
    "\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "data.to_csv(f\"{data_folder_path}/scraped_all/combined_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally to combine the two we read them in again, and save them to one combined csv file. We then delete the old csv's to save space (hence they are not in the repository anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_1 = pd.read_csv(f\"{data_folder_path}/scraped_all/combined_1.csv\")\n",
    "part_2 = pd.read_csv(f\"{data_folder_path}/scraped_all/combined_2.csv\")\n",
    "\n",
    "combined = pd.concat([part_1, part_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(f\"{data_folder_path}/saved_data/country_to_country_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot relationships between countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_csv(f\"{data_folder_path}/saved_data/country_to_country_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_f = combined.drop(columns = [\"Date\", \"Unnamed: 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>Angola</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Azerbaijan</th>\n",
       "      <th>Bahrain</th>\n",
       "      <th>...</th>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>United States</th>\n",
       "      <th>Uruguay</th>\n",
       "      <th>Uzbekistan</th>\n",
       "      <th>Venezuela</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yemen</th>\n",
       "      <th>Zambia</th>\n",
       "      <th>Zimbabwe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>61.153794</td>\n",
       "      <td>0.722672</td>\n",
       "      <td>0.407648</td>\n",
       "      <td>0.233930</td>\n",
       "      <td>0.123163</td>\n",
       "      <td>1.084218</td>\n",
       "      <td>0.690159</td>\n",
       "      <td>0.186505</td>\n",
       "      <td>3.598944</td>\n",
       "      <td>0.778591</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125398</td>\n",
       "      <td>0.818044</td>\n",
       "      <td>0.913777</td>\n",
       "      <td>0.240189</td>\n",
       "      <td>4.074993</td>\n",
       "      <td>0.431421</td>\n",
       "      <td>0.033245</td>\n",
       "      <td>0.589670</td>\n",
       "      <td>0.060320</td>\n",
       "      <td>0.812661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>0.097081</td>\n",
       "      <td>29.539962</td>\n",
       "      <td>0.046415</td>\n",
       "      <td>0.041323</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>0.186553</td>\n",
       "      <td>0.033172</td>\n",
       "      <td>0.086125</td>\n",
       "      <td>0.395863</td>\n",
       "      <td>0.060133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098717</td>\n",
       "      <td>0.104755</td>\n",
       "      <td>0.070581</td>\n",
       "      <td>0.027824</td>\n",
       "      <td>0.053563</td>\n",
       "      <td>0.037084</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.039245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>0.260947</td>\n",
       "      <td>0.084421</td>\n",
       "      <td>39.857927</td>\n",
       "      <td>0.356128</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>0.082390</td>\n",
       "      <td>0.042973</td>\n",
       "      <td>0.097514</td>\n",
       "      <td>0.228640</td>\n",
       "      <td>0.656803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693201</td>\n",
       "      <td>0.115633</td>\n",
       "      <td>0.097019</td>\n",
       "      <td>0.135504</td>\n",
       "      <td>0.097806</td>\n",
       "      <td>0.259118</td>\n",
       "      <td>0.021097</td>\n",
       "      <td>0.518425</td>\n",
       "      <td>0.622939</td>\n",
       "      <td>0.670658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Samoa</th>\n",
       "      <td>0.002766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.022266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>0.011695</td>\n",
       "      <td>0.033549</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.051678</td>\n",
       "      <td>0.036054</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>0.016540</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>0.023211</td>\n",
       "      <td>0.009281</td>\n",
       "      <td>0.055879</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>0.104778</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.005676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Afghanistan    Albania    Algeria    Angola  Argentina  \\\n",
       "Target country                                                           \n",
       "Afghanistan       61.153794   0.722672   0.407648  0.233930   0.123163   \n",
       "Albania            0.097081  29.539962   0.046415  0.041323   0.016827   \n",
       "Algeria            0.260947   0.084421  39.857927  0.356128   0.073552   \n",
       "American Samoa     0.002766        NaN   0.001862  0.001263   0.000168   \n",
       "Andorra            0.011695   0.033549   0.012754  0.008019   0.051678   \n",
       "\n",
       "                 Armenia  Australia   Austria  Azerbaijan   Bahrain  ...  \\\n",
       "Target country                                                       ...   \n",
       "Afghanistan     1.084218   0.690159  0.186505    3.598944  0.778591  ...   \n",
       "Albania         0.186553   0.033172  0.086125    0.395863  0.060133  ...   \n",
       "Algeria         0.082390   0.042973  0.097514    0.228640  0.656803  ...   \n",
       "American Samoa  0.000647   0.010499  0.002519    0.000508  0.000562  ...   \n",
       "Andorra         0.036054   0.005952  0.041431    0.016540  0.007418  ...   \n",
       "\n",
       "                United Arab Emirates  United Kingdom  United States   Uruguay  \\\n",
       "Target country                                                                  \n",
       "Afghanistan                 1.125398        0.818044       0.913777  0.240189   \n",
       "Albania                     0.098717        0.104755       0.070581  0.027824   \n",
       "Algeria                     0.693201        0.115633       0.097019  0.135504   \n",
       "American Samoa              0.003072        0.007657       0.022266       NaN   \n",
       "Andorra                     0.011919        0.023211       0.009281  0.055879   \n",
       "\n",
       "                Uzbekistan  Venezuela   Vietnam     Yemen    Zambia  Zimbabwe  \n",
       "Target country                                                                 \n",
       "Afghanistan       4.074993   0.431421  0.033245  0.589670  0.060320  0.812661  \n",
       "Albania           0.053563   0.037084  0.002799  0.023954  0.019373  0.039245  \n",
       "Algeria           0.097806   0.259118  0.021097  0.518425  0.622939  0.670658  \n",
       "American Samoa         NaN   0.000184  0.000111  0.000850       NaN  0.003364  \n",
       "Andorra           0.011520   0.104778  0.000376  0.007867  0.021544  0.005676  \n",
       "\n",
       "[5 rows x 169 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_f = combined_f.groupby([\"Target country\"]).mean().sort_values(by = \"Target country\")\n",
    "combined_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.6178757656968"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_f[\"Albania\"].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
